{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Machine_translation_Eng_Hin.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/hlamba28/Word-Level-Eng-Mar-NMT/blob/master/WordLevelEngMarNMT.ipynb","timestamp":1561635753552}],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xmiTvHqHvEQ3","colab_type":"text"},"source":["### Datasets\n","http://www.manythings.org/anki/  "]},{"cell_type":"code","metadata":{"id":"kvF8GCmXvEQ6","colab_type":"code","outputId":"376d0087-826d-4117-c2e6-d862548d5c13","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1561659677781,"user_tz":-330,"elapsed":2591,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["import pandas as pd\n","import numpy as np\n","import string\n","from string import digits\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import re\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Input, LSTM, Embedding, Dense\n","from keras.models import Model"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hD5gtEM4v_vH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"fdf872cc-19a9-4f97-895d-3b9a07038a02","executionInfo":{"status":"ok","timestamp":1561659669121,"user_tz":-330,"elapsed":25832,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["# Run this cell to mount your Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wbCwKcPqvERD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"d4d0eedc-0614-4acb-c97b-1ecb631791ad","executionInfo":{"status":"ok","timestamp":1561659682127,"user_tz":-330,"elapsed":964,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["lines= pd.read_table('/content/drive/My Drive/MT/hin.txt', names=['eng', 'hin'])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5jZOcEIYvERH","colab_type":"code","outputId":"0760cd48-12cd-45dc-b507-2c090a271e0e","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1561638392219,"user_tz":-330,"elapsed":1373,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["lines.shape"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2831, 2)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"UhYH-3mJvERN","colab_type":"code","colab":{}},"source":["# Lowercase all characters\n","lines.eng=lines.eng.apply(lambda x: x.lower())\n","lines.hin=lines.hin.apply(lambda x: x.lower())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5y0Hb4JvERS","colab_type":"code","colab":{}},"source":["# Remove quotes\n","lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n","lines.hin=lines.hin.apply(lambda x: re.sub(\"'\", '', x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDe6zwfMvERV","colab_type":"code","colab":{}},"source":["exclude = set(string.punctuation) # Set of all special characters\n","# Remove all the special characters\n","lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n","lines.hin=lines.hin.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgnNPT_QvERZ","colab_type":"code","colab":{}},"source":["# Remove all numbers from text\n","remove_digits = str.maketrans('', '', digits)\n","lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n","lines.hin = lines.hin.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxhKXFHGvERc","colab_type":"code","colab":{}},"source":["# Remove extra spaces\n","lines.eng=lines.eng.apply(lambda x: x.strip())\n","lines.hin=lines.hin.apply(lambda x: x.strip())\n","lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n","lines.hin=lines.hin.apply(lambda x: re.sub(\" +\", \" \", x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gAJvjt7hvERf","colab_type":"code","colab":{}},"source":["# Add start and end tokens to target sequences\n","lines.hin = lines.hin.apply(lambda x : 'START_ '+ x + ' _END')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8hUAM1nvERk","colab_type":"code","outputId":"110ed86f-d7d7-429d-f650-b3b1b6c034d9","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1561638421653,"user_tz":-330,"elapsed":1151,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["lines.sample(10)"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>hin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>84</th>\n","      <td>i like both</td>\n","      <td>START_ मुझे दोनो पसंद हैं। _END</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>were in a hurry</td>\n","      <td>START_ हम जल्दी में हैं। _END</td>\n","    </tr>\n","    <tr>\n","      <th>1791</th>\n","      <td>you must get rid of such a habit</td>\n","      <td>START_ तुम्हे इस तरह की आदत तोड़ देनी चाहिए। _END</td>\n","    </tr>\n","    <tr>\n","      <th>1148</th>\n","      <td>i dont know what to study</td>\n","      <td>START_ मुझे समझ में नहीं आ रहा कि क्या पढ़ूँ। ...</td>\n","    </tr>\n","    <tr>\n","      <th>2791</th>\n","      <td>this morning the weather was so bad that i had...</td>\n","      <td>START_ आज सुबह मौसम इतना खराब था कि मुझे टैक्स...</td>\n","    </tr>\n","    <tr>\n","      <th>2733</th>\n","      <td>this car has enough power to go up the mountai...</td>\n","      <td>START_ गाड़ी में आसानी से पहाड़ चढ़ने लायक जान...</td>\n","    </tr>\n","    <tr>\n","      <th>1084</th>\n","      <td>the haze enveloped london</td>\n","      <td>START_ लंदन में धुंध छा गई थी। _END</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>its mine not his</td>\n","      <td>START_ मेरा है उसका नहीं। _END</td>\n","    </tr>\n","    <tr>\n","      <th>2244</th>\n","      <td>all you have to do is follow his advice</td>\n","      <td>START_ तुम्हे बस उसकी सलाह के मुताबिक काम करना...</td>\n","    </tr>\n","    <tr>\n","      <th>538</th>\n","      <td>i agree to this plan</td>\n","      <td>START_ मैं इस योजना से सहमत हूँ। _END</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    eng                                                hin\n","84                                          i like both                    START_ मुझे दोनो पसंद हैं। _END\n","283                                     were in a hurry                      START_ हम जल्दी में हैं। _END\n","1791                   you must get rid of such a habit  START_ तुम्हे इस तरह की आदत तोड़ देनी चाहिए। _END\n","1148                          i dont know what to study  START_ मुझे समझ में नहीं आ रहा कि क्या पढ़ूँ। ...\n","2791  this morning the weather was so bad that i had...  START_ आज सुबह मौसम इतना खराब था कि मुझे टैक्स...\n","2733  this car has enough power to go up the mountai...  START_ गाड़ी में आसानी से पहाड़ चढ़ने लायक जान...\n","1084                          the haze enveloped london                START_ लंदन में धुंध छा गई थी। _END\n","406                                    its mine not his                     START_ मेरा है उसका नहीं। _END\n","2244            all you have to do is follow his advice  START_ तुम्हे बस उसकी सलाह के मुताबिक काम करना...\n","538                                i agree to this plan              START_ मैं इस योजना से सहमत हूँ। _END"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"QsTduxi-vERp","colab_type":"code","colab":{}},"source":["# Vocabulary of English\n","all_eng_words=set()\n","for eng in lines.eng:\n","    for word in eng.split():\n","        if word not in all_eng_words:\n","            all_eng_words.add(word)\n","\n","# Vocabulary of Hindi\n","all_hindi_words=set()\n","for hin in lines.hin:\n","    for word in hin.split():\n","        if word not in all_hindi_words:\n","            all_hindi_words.add(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rJOUUrPvERs","colab_type":"code","outputId":"d302862e-ec76-4acb-f08f-983f8ca0ea38","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1561638431044,"user_tz":-330,"elapsed":1139,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["# Max Length of source sequence\n","length_list=[]\n","for l in lines.eng:\n","    length_list.append(len(l.split(' ')))\n","max_length_src = np.max(length_list)\n","max_length_src"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"kOAv-01zvERw","colab_type":"code","outputId":"b55bdda8-9881-4520-9306-397290a130ba","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1561638434878,"user_tz":-330,"elapsed":1104,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["# Max Length of target sequence\n","length_list=[]\n","for l in lines.hin:\n","    length_list.append(len(l.split(' ')))\n","max_length_tar = np.max(length_list)\n","max_length_tar"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"Bmikfa6JvER0","colab_type":"code","outputId":"5addaf27-b74b-40f0-8eed-bb2b79ac0d15","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1561638442133,"user_tz":-330,"elapsed":1093,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["input_words = sorted(list(all_eng_words))\n","target_words = sorted(list(all_hindi_words))\n","num_encoder_tokens = len(all_eng_words)\n","num_decoder_tokens = len(all_hindi_words)\n","num_encoder_tokens, num_decoder_tokens"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2361, 3003)"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"OU4ybgWzvER4","colab_type":"code","outputId":"f3f7149e-ab8c-4a94-aac2-98c442e03e58","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1561638445782,"user_tz":-330,"elapsed":941,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["num_decoder_tokens += 1 # For zero padding\n","num_decoder_tokens"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3004"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"B1yUpmZbvER-","colab_type":"code","colab":{}},"source":["input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n","target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bH6ydfFxvESB","colab_type":"code","colab":{}},"source":["reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n","reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCryxh5VvESG","colab_type":"code","outputId":"9e1e7a21-1a47-48ab-969b-3f74b1ac941d","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1561638458967,"user_tz":-330,"elapsed":865,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["lines = shuffle(lines)\n","lines.head(10)"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>hin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2325</th>\n","      <td>if only i had known the answer yesterday</td>\n","      <td>START_ काश मुझे यह जवाब कल पता होता _END</td>\n","    </tr>\n","    <tr>\n","      <th>814</th>\n","      <td>he is used to hard work</td>\n","      <td>START_ उसको मेहनत करने की आदत है। _END</td>\n","    </tr>\n","    <tr>\n","      <th>258</th>\n","      <td>he speaks arabic</td>\n","      <td>START_ वह अरबी बोलता है। _END</td>\n","    </tr>\n","    <tr>\n","      <th>858</th>\n","      <td>they stood face to face</td>\n","      <td>START_ वे आमनेसामने खड़े हुए। _END</td>\n","    </tr>\n","    <tr>\n","      <th>2255</th>\n","      <td>how about adding a little bit more salt</td>\n","      <td>START_ थोड़ा और नमक डाल दोगे _END</td>\n","    </tr>\n","    <tr>\n","      <th>2770</th>\n","      <td>he promised me that he would be more careful i...</td>\n","      <td>START_ उसने मुझसे वादा किया था कि वह आगे से ज़...</td>\n","    </tr>\n","    <tr>\n","      <th>994</th>\n","      <td>did the police arrest tom</td>\n","      <td>START_ पुलीस ने टॉम को गिरफ़्तार किया क्या _END</td>\n","    </tr>\n","    <tr>\n","      <th>1740</th>\n","      <td>it wont take long to do the job</td>\n","      <td>START_ इस काम को करने में ज़्यादा देर नहीं लगे...</td>\n","    </tr>\n","    <tr>\n","      <th>821</th>\n","      <td>he was more than a king</td>\n","      <td>START_ वह एक राजा से बहुत ज़्यादा था। _END</td>\n","    </tr>\n","    <tr>\n","      <th>1300</th>\n","      <td>the room smelled of tobacco</td>\n","      <td>START_ कमरे में तम्बाकू की महक थी। _END</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    eng                                                hin\n","2325           if only i had known the answer yesterday           START_ काश मुझे यह जवाब कल पता होता _END\n","814                             he is used to hard work             START_ उसको मेहनत करने की आदत है। _END\n","258                                    he speaks arabic                      START_ वह अरबी बोलता है। _END\n","858                             they stood face to face                 START_ वे आमनेसामने खड़े हुए। _END\n","2255            how about adding a little bit more salt                  START_ थोड़ा और नमक डाल दोगे _END\n","2770  he promised me that he would be more careful i...  START_ उसने मुझसे वादा किया था कि वह आगे से ज़...\n","994                           did the police arrest tom    START_ पुलीस ने टॉम को गिरफ़्तार किया क्या _END\n","1740                    it wont take long to do the job  START_ इस काम को करने में ज़्यादा देर नहीं लगे...\n","821                             he was more than a king         START_ वह एक राजा से बहुत ज़्यादा था। _END\n","1300                        the room smelled of tobacco            START_ कमरे में तम्बाकू की महक थी। _END"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"y_JW5CrsvESL","colab_type":"code","outputId":"2df29d28-3ee3-4b21-9149-b711dec82242","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1561638471915,"user_tz":-330,"elapsed":1549,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["# Train - Test Split\n","X, y = lines.eng, lines.hin\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05)\n","X_train.shape, X_test.shape"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2689,), (142,))"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"x0ns_QWwvESR","colab_type":"text"},"source":["#### Save the train and test dataframes for reproducing the results later, as they are shuffled."]},{"cell_type":"code","metadata":{"id":"uBOrSUkTvESS","colab_type":"code","colab":{}},"source":["\"\"\"X_train.to_pickle('Weights_Hin/X_train.pkl')\n","X_test.to_pickle('Weights_Hin/X_test.pkl')\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ju_WMFmxvESV","colab_type":"code","colab":{}},"source":["def generate_batch(X = X_train, y = y_train, batch_size = 32):\n","    ''' Generate a batch of data '''\n","    while True:\n","        for j in range(0, len(X), batch_size):\n","            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n","            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n","            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n","            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n","                for t, word in enumerate(input_text.split()):\n","                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n","                for t, word in enumerate(target_text.split()):\n","                    if t<len(target_text.split())-1:\n","                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n","                    if t>0:\n","                        # decoder target sequence (one hot encoded)\n","                        # does not include the START_ token\n","                        # Offset by one timestep\n","                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n","            yield([encoder_input_data, decoder_input_data], decoder_target_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dAabprvvESY","colab_type":"text"},"source":["### Encoder - Decoder Model Architecture"]},{"cell_type":"code","metadata":{"id":"CThUIvIwvESZ","colab_type":"code","colab":{}},"source":["latent_dim = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILfSlsdZvESe","colab_type":"code","colab":{}},"source":["# Encoder\n","encoder_inputs = Input(shape=(None,))\n","enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n","encoder_lstm = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXD3PkyGvESg","colab_type":"code","colab":{}},"source":["# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None,))\n","dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n","dec_emb = dec_emb_layer(decoder_inputs)\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(dec_emb,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_W2aB_pavESj","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mx1islCCvESo","colab_type":"code","colab":{}},"source":["train_samples = len(X_train)\n","val_samples = len(X_test)\n","batch_size = 32\n","\n","epochs = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbIOjM_ovESr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"600ff819-cb2d-4fbb-fd50-91481a78dcaf","executionInfo":{"status":"ok","timestamp":1561639750473,"user_tz":-330,"elapsed":1139506,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n","                    steps_per_epoch = train_samples//batch_size,\n","                    epochs=epochs,\n","                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n","                    validation_steps = val_samples//batch_size)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","84/84 [==============================] - 14s 169ms/step - loss: 7.0257 - acc: 0.1242 - val_loss: 6.0294 - val_acc: 0.1295\n","Epoch 2/100\n","84/84 [==============================] - 12s 137ms/step - loss: 5.9747 - acc: 0.1281 - val_loss: 5.9494 - val_acc: 0.1320\n","Epoch 3/100\n","84/84 [==============================] - 11s 136ms/step - loss: 5.8787 - acc: 0.1282 - val_loss: 5.8240 - val_acc: 0.1352\n","Epoch 4/100\n","84/84 [==============================] - 12s 137ms/step - loss: 5.7413 - acc: 0.1283 - val_loss: 5.7252 - val_acc: 0.1342\n","Epoch 5/100\n","84/84 [==============================] - 11s 136ms/step - loss: 5.5893 - acc: 0.1302 - val_loss: 5.6677 - val_acc: 0.1395\n","Epoch 6/100\n","84/84 [==============================] - 11s 136ms/step - loss: 5.4801 - acc: 0.1442 - val_loss: 5.6191 - val_acc: 0.1487\n","Epoch 7/100\n","84/84 [==============================] - 11s 137ms/step - loss: 5.3842 - acc: 0.1530 - val_loss: 5.4654 - val_acc: 0.1719\n","Epoch 8/100\n","84/84 [==============================] - 12s 137ms/step - loss: 5.2896 - acc: 0.1603 - val_loss: 5.3439 - val_acc: 0.1736\n","Epoch 9/100\n","84/84 [==============================] - 11s 136ms/step - loss: 5.2071 - acc: 0.1678 - val_loss: 5.3964 - val_acc: 0.1807\n","Epoch 10/100\n","84/84 [==============================] - 11s 137ms/step - loss: 5.1360 - acc: 0.1776 - val_loss: 5.3897 - val_acc: 0.1885\n","Epoch 11/100\n","84/84 [==============================] - 11s 136ms/step - loss: 5.0722 - acc: 0.1876 - val_loss: 5.3881 - val_acc: 0.1849\n","Epoch 12/100\n","84/84 [==============================] - 11s 134ms/step - loss: 5.0083 - acc: 0.1919 - val_loss: 5.2598 - val_acc: 0.1943\n","Epoch 13/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.9519 - acc: 0.1949 - val_loss: 5.1618 - val_acc: 0.1958\n","Epoch 14/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.8980 - acc: 0.1985 - val_loss: 5.2503 - val_acc: 0.1971\n","Epoch 15/100\n","84/84 [==============================] - 11s 136ms/step - loss: 4.8466 - acc: 0.2011 - val_loss: 5.2653 - val_acc: 0.2002\n","Epoch 16/100\n","84/84 [==============================] - 12s 137ms/step - loss: 4.7925 - acc: 0.2051 - val_loss: 5.2681 - val_acc: 0.1940\n","Epoch 17/100\n","84/84 [==============================] - 11s 136ms/step - loss: 4.7440 - acc: 0.2083 - val_loss: 5.1593 - val_acc: 0.2064\n","Epoch 18/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.6960 - acc: 0.2126 - val_loss: 5.0526 - val_acc: 0.2071\n","Epoch 19/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.6384 - acc: 0.2172 - val_loss: 5.1447 - val_acc: 0.1969\n","Epoch 20/100\n","84/84 [==============================] - 11s 136ms/step - loss: 4.5744 - acc: 0.2225 - val_loss: 5.1532 - val_acc: 0.2021\n","Epoch 21/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.5207 - acc: 0.2270 - val_loss: 5.1796 - val_acc: 0.1980\n","Epoch 22/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.4706 - acc: 0.2311 - val_loss: 5.0635 - val_acc: 0.2076\n","Epoch 23/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.4189 - acc: 0.2360 - val_loss: 4.9446 - val_acc: 0.2153\n","Epoch 24/100\n","84/84 [==============================] - 11s 136ms/step - loss: 4.3652 - acc: 0.2411 - val_loss: 5.0602 - val_acc: 0.2026\n","Epoch 25/100\n","84/84 [==============================] - 11s 134ms/step - loss: 4.3111 - acc: 0.2476 - val_loss: 5.0841 - val_acc: 0.2211\n","Epoch 26/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.2519 - acc: 0.2549 - val_loss: 5.1534 - val_acc: 0.2122\n","Epoch 27/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.1910 - acc: 0.2601 - val_loss: 4.9954 - val_acc: 0.2204\n","Epoch 28/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.1407 - acc: 0.2680 - val_loss: 4.8675 - val_acc: 0.2256\n","Epoch 29/100\n","84/84 [==============================] - 11s 135ms/step - loss: 4.0875 - acc: 0.2751 - val_loss: 5.0112 - val_acc: 0.2209\n","Epoch 30/100\n","84/84 [==============================] - 11s 136ms/step - loss: 4.0365 - acc: 0.2812 - val_loss: 5.0185 - val_acc: 0.2370\n","Epoch 31/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.9851 - acc: 0.2889 - val_loss: 5.0856 - val_acc: 0.2246\n","Epoch 32/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.9346 - acc: 0.2947 - val_loss: 4.9233 - val_acc: 0.2411\n","Epoch 33/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.8762 - acc: 0.3012 - val_loss: 4.7866 - val_acc: 0.2466\n","Epoch 34/100\n","84/84 [==============================] - 11s 136ms/step - loss: 3.8193 - acc: 0.3112 - val_loss: 4.9653 - val_acc: 0.2362\n","Epoch 35/100\n","84/84 [==============================] - 11s 136ms/step - loss: 3.7617 - acc: 0.3184 - val_loss: 4.9803 - val_acc: 0.2460\n","Epoch 36/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.7049 - acc: 0.3276 - val_loss: 5.0259 - val_acc: 0.2436\n","Epoch 37/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.6457 - acc: 0.3342 - val_loss: 4.8731 - val_acc: 0.2585\n","Epoch 38/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.5920 - acc: 0.3423 - val_loss: 4.7261 - val_acc: 0.2761\n","Epoch 39/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.5427 - acc: 0.3453 - val_loss: 4.9406 - val_acc: 0.2560\n","Epoch 40/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.4879 - acc: 0.3531 - val_loss: 4.9226 - val_acc: 0.2720\n","Epoch 41/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.4393 - acc: 0.3604 - val_loss: 5.0117 - val_acc: 0.2548\n","Epoch 42/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.3886 - acc: 0.3661 - val_loss: 4.8413 - val_acc: 0.2652\n","Epoch 43/100\n","84/84 [==============================] - 11s 133ms/step - loss: 3.3464 - acc: 0.3703 - val_loss: 4.6623 - val_acc: 0.2894\n","Epoch 44/100\n","84/84 [==============================] - 11s 134ms/step - loss: 3.2956 - acc: 0.3771 - val_loss: 4.9182 - val_acc: 0.2595\n","Epoch 45/100\n","84/84 [==============================] - 11s 134ms/step - loss: 3.2401 - acc: 0.3850 - val_loss: 4.8880 - val_acc: 0.2737\n","Epoch 46/100\n","84/84 [==============================] - 11s 134ms/step - loss: 3.1882 - acc: 0.3943 - val_loss: 5.0029 - val_acc: 0.2581\n","Epoch 47/100\n","84/84 [==============================] - 11s 134ms/step - loss: 3.1434 - acc: 0.3972 - val_loss: 4.8112 - val_acc: 0.2755\n","Epoch 48/100\n","84/84 [==============================] - 11s 135ms/step - loss: 3.0933 - acc: 0.4058 - val_loss: 4.6324 - val_acc: 0.2905\n","Epoch 49/100\n","84/84 [==============================] - 11s 134ms/step - loss: 3.0409 - acc: 0.4128 - val_loss: 4.8871 - val_acc: 0.2727\n","Epoch 50/100\n","84/84 [==============================] - 11s 132ms/step - loss: 2.9954 - acc: 0.4201 - val_loss: 4.8849 - val_acc: 0.2911\n","Epoch 51/100\n","84/84 [==============================] - 11s 134ms/step - loss: 2.9478 - acc: 0.4261 - val_loss: 5.0054 - val_acc: 0.2702\n","Epoch 52/100\n","84/84 [==============================] - 11s 135ms/step - loss: 2.9086 - acc: 0.4329 - val_loss: 4.8278 - val_acc: 0.2778\n","Epoch 53/100\n","84/84 [==============================] - 11s 135ms/step - loss: 2.8689 - acc: 0.4381 - val_loss: 4.6230 - val_acc: 0.2973\n","Epoch 54/100\n","84/84 [==============================] - 11s 133ms/step - loss: 2.8378 - acc: 0.4414 - val_loss: 4.8947 - val_acc: 0.2699\n","Epoch 55/100\n","84/84 [==============================] - 11s 133ms/step - loss: 2.7917 - acc: 0.4495 - val_loss: 4.8556 - val_acc: 0.2989\n","Epoch 56/100\n","84/84 [==============================] - 11s 134ms/step - loss: 2.7426 - acc: 0.4575 - val_loss: 5.0113 - val_acc: 0.2784\n","Epoch 57/100\n","84/84 [==============================] - 11s 135ms/step - loss: 2.6993 - acc: 0.4631 - val_loss: 4.8407 - val_acc: 0.2822\n","Epoch 58/100\n","84/84 [==============================] - 11s 135ms/step - loss: 2.6503 - acc: 0.4722 - val_loss: 4.6081 - val_acc: 0.3040\n","Epoch 59/100\n","84/84 [==============================] - 11s 135ms/step - loss: 2.6025 - acc: 0.4805 - val_loss: 4.8916 - val_acc: 0.2898\n","Epoch 60/100\n","84/84 [==============================] - 11s 133ms/step - loss: 2.5612 - acc: 0.4883 - val_loss: 4.8734 - val_acc: 0.3050\n","Epoch 61/100\n","84/84 [==============================] - 11s 135ms/step - loss: 2.5193 - acc: 0.4962 - val_loss: 5.0682 - val_acc: 0.2806\n","Epoch 62/100\n","84/84 [==============================] - 11s 134ms/step - loss: 2.4778 - acc: 0.5037 - val_loss: 4.8537 - val_acc: 0.2892\n","Epoch 63/100\n","84/84 [==============================] - 11s 134ms/step - loss: 2.4391 - acc: 0.5105 - val_loss: 4.6149 - val_acc: 0.3160\n","Epoch 64/100\n","84/84 [==============================] - 11s 134ms/step - loss: 2.4004 - acc: 0.5179 - val_loss: 4.9146 - val_acc: 0.2834\n","Epoch 65/100\n","84/84 [==============================] - 11s 133ms/step - loss: 2.3695 - acc: 0.5231 - val_loss: 4.8981 - val_acc: 0.2963\n","Epoch 66/100\n","84/84 [==============================] - 11s 132ms/step - loss: 2.3339 - acc: 0.5304 - val_loss: 5.0925 - val_acc: 0.2815\n","Epoch 67/100\n","84/84 [==============================] - 11s 132ms/step - loss: 2.2962 - acc: 0.5386 - val_loss: 4.9027 - val_acc: 0.2901\n","Epoch 68/100\n","84/84 [==============================] - 11s 134ms/step - loss: 2.2647 - acc: 0.5431 - val_loss: 4.6565 - val_acc: 0.3137\n","Epoch 69/100\n","84/84 [==============================] - 11s 133ms/step - loss: 2.2285 - acc: 0.5493 - val_loss: 4.9951 - val_acc: 0.2811\n","Epoch 70/100\n","84/84 [==============================] - 11s 132ms/step - loss: 2.1914 - acc: 0.5584 - val_loss: 4.9458 - val_acc: 0.3019\n","Epoch 71/100\n","84/84 [==============================] - 11s 134ms/step - loss: 2.1605 - acc: 0.5636 - val_loss: 5.1290 - val_acc: 0.2877\n","Epoch 72/100\n","84/84 [==============================] - 11s 135ms/step - loss: 2.1176 - acc: 0.5713 - val_loss: 4.9598 - val_acc: 0.2972\n","Epoch 73/100\n","84/84 [==============================] - 11s 136ms/step - loss: 2.0841 - acc: 0.5779 - val_loss: 4.6943 - val_acc: 0.3132\n","Epoch 74/100\n","84/84 [==============================] - 11s 135ms/step - loss: 2.0529 - acc: 0.5850 - val_loss: 5.0048 - val_acc: 0.2943\n","Epoch 75/100\n","84/84 [==============================] - 11s 136ms/step - loss: 2.0134 - acc: 0.5929 - val_loss: 4.9802 - val_acc: 0.3115\n","Epoch 76/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.9818 - acc: 0.5993 - val_loss: 5.1970 - val_acc: 0.2938\n","Epoch 77/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.9543 - acc: 0.6056 - val_loss: 4.9930 - val_acc: 0.2972\n","Epoch 78/100\n","84/84 [==============================] - 11s 134ms/step - loss: 1.9227 - acc: 0.6112 - val_loss: 4.7356 - val_acc: 0.3189\n","Epoch 79/100\n","84/84 [==============================] - 11s 136ms/step - loss: 1.8909 - acc: 0.6183 - val_loss: 5.0966 - val_acc: 0.2903\n","Epoch 80/100\n","84/84 [==============================] - 11s 134ms/step - loss: 1.8646 - acc: 0.6244 - val_loss: 5.0220 - val_acc: 0.3144\n","Epoch 81/100\n","84/84 [==============================] - 11s 134ms/step - loss: 1.8348 - acc: 0.6301 - val_loss: 5.2390 - val_acc: 0.2906\n","Epoch 82/100\n","84/84 [==============================] - 11s 134ms/step - loss: 1.8031 - acc: 0.6356 - val_loss: 5.0787 - val_acc: 0.3086\n","Epoch 83/100\n","84/84 [==============================] - 11s 134ms/step - loss: 1.7708 - acc: 0.6446 - val_loss: 4.7791 - val_acc: 0.3170\n","Epoch 84/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.7468 - acc: 0.6499 - val_loss: 5.1494 - val_acc: 0.2944\n","Epoch 85/100\n","84/84 [==============================] - 11s 134ms/step - loss: 1.7180 - acc: 0.6558 - val_loss: 5.1206 - val_acc: 0.3095\n","Epoch 86/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.7084 - acc: 0.6579 - val_loss: 5.3369 - val_acc: 0.2883\n","Epoch 87/100\n","84/84 [==============================] - 11s 134ms/step - loss: 1.6659 - acc: 0.6670 - val_loss: 5.1118 - val_acc: 0.3026\n","Epoch 88/100\n","84/84 [==============================] - 11s 136ms/step - loss: 1.6387 - acc: 0.6738 - val_loss: 4.8313 - val_acc: 0.3257\n","Epoch 89/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.6154 - acc: 0.6771 - val_loss: 5.1989 - val_acc: 0.3088\n","Epoch 90/100\n","84/84 [==============================] - 11s 137ms/step - loss: 1.5924 - acc: 0.6811 - val_loss: 5.1305 - val_acc: 0.3190\n","Epoch 91/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.5633 - acc: 0.6906 - val_loss: 5.3728 - val_acc: 0.3039\n","Epoch 92/100\n","84/84 [==============================] - 11s 136ms/step - loss: 1.5442 - acc: 0.6946 - val_loss: 5.2138 - val_acc: 0.3022\n","Epoch 93/100\n","84/84 [==============================] - 11s 134ms/step - loss: 1.5189 - acc: 0.6983 - val_loss: 4.9218 - val_acc: 0.3174\n","Epoch 94/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.4997 - acc: 0.7029 - val_loss: 5.2823 - val_acc: 0.2967\n","Epoch 95/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.4716 - acc: 0.7085 - val_loss: 5.2340 - val_acc: 0.3132\n","Epoch 96/100\n","84/84 [==============================] - 11s 136ms/step - loss: 1.4517 - acc: 0.7133 - val_loss: 5.4612 - val_acc: 0.2956\n","Epoch 97/100\n","84/84 [==============================] - 11s 136ms/step - loss: 1.4250 - acc: 0.7191 - val_loss: 5.2363 - val_acc: 0.3063\n","Epoch 98/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.4017 - acc: 0.7236 - val_loss: 4.9161 - val_acc: 0.3349\n","Epoch 99/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.3870 - acc: 0.7253 - val_loss: 5.3377 - val_acc: 0.3008\n","Epoch 100/100\n","84/84 [==============================] - 11s 135ms/step - loss: 1.3731 - acc: 0.7288 - val_loss: 5.2905 - val_acc: 0.3087\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6b698acef0>"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"markdown","metadata":{"id":"0ohPBp_avESt","colab_type":"text"},"source":["### Always remember to save the weights"]},{"cell_type":"code","metadata":{"id":"71QghD79vESt","colab_type":"code","colab":{}},"source":["model.save_weights('nmt_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TKsni4rNvESx","colab_type":"text"},"source":["### Load the weights, if you close the application"]},{"cell_type":"code","metadata":{"id":"5TEDIMcXvESy","colab_type":"code","colab":{}},"source":["model.load_weights('nmt_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ll-gkR0GvES1","colab_type":"text"},"source":["### Inference Setup"]},{"cell_type":"code","metadata":{"id":"8sE30yZ3vES2","colab_type":"code","colab":{}},"source":["# Encode the input sequence to get the \"thought vectors\"\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","# Decoder setup\n","# Below tensors will hold the states of the previous time step\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n","\n","# To predict the next word in the sequence, set the initial states to the states from the previous time step\n","decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n","decoder_states2 = [state_h2, state_c2]\n","decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n","\n","# Final decoder model\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs2] + decoder_states2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELXQBwWfvES_","colab_type":"text"},"source":["### Decode sample sequeces"]},{"cell_type":"code","metadata":{"id":"txbDRVaFvES_","colab_type":"code","colab":{}},"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1,1))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0] = target_token_index['START_']\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += ' '+sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '_END' or\n","           len(decoded_sentence) > 50):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1,1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kEOn9gHlvETB","colab_type":"text"},"source":["### Evaluation on Train Dataset"]},{"cell_type":"code","metadata":{"id":"sqRnvdiyvETC","colab_type":"code","colab":{}},"source":["train_gen = generate_batch(X_train, y_train, batch_size = 1)\n","k=-1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q44z1FQivETE","colab_type":"code","outputId":"d18b60aa-2fef-4d95-b7d8-bbe1f23ce142","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1561639784966,"user_tz":-330,"elapsed":1353,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Hindi Translation:', decoded_sentence[:-4])"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Input English sentence: is that a cat\n","Actual Hindi Translation:  वह बिल्ली है क्या \n","Predicted Hindi Translation:  वह खबर रखना चाहिए। \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1FQKBpOgvETH","colab_type":"code","outputId":"31e2dec7-95b6-476e-a2d0-14a10c622ae0","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1561639795104,"user_tz":-330,"elapsed":924,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Hindi Translation:', decoded_sentence[:-4])"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Input English sentence: she said to herself i am very happy\n","Actual Hindi Translation:  उसने अपने आप से कहा मैं बहुत खुश हूँ \n","Predicted Hindi Translation:  उसने अपने पैसे करने की कोशिश करी थी। \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-GB230nZvETJ","colab_type":"code","outputId":"c0ea1608-b1f5-4c27-c62d-2100d5a43a94","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1561639809747,"user_tz":-330,"elapsed":994,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Hindi Translation:', decoded_sentence[:-4])"],"execution_count":78,"outputs":[{"output_type":"stream","text":["Input English sentence: a fire broke out near my house\n","Actual Hindi Translation:  मेरे घर के पड़ोस में आग लग गई थी। \n","Predicted Hindi Translation:  मेरे घर के लिए बहुत सारे विद्यार्थी थे। \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sdr_QV5uvETM","colab_type":"code","outputId":"44339a07-4a9d-4f31-bcd4-0820c156ab6a","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1561639824800,"user_tz":-330,"elapsed":963,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["k+=1\n","(input_seq, actual_output), _ = next(train_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_train[k:k+1].values[0])\n","print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n","print('Predicted Hindi Translation:', decoded_sentence[:-4])"],"execution_count":79,"outputs":[{"output_type":"stream","text":["Input English sentence: im very thirsty\n","Actual Hindi Translation:  मुझे बहुत प्यास लगी है। \n","Predicted Hindi Translation:  मुझे बहुत प्यास लगी है। \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yMQ5gswRvEVp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aV_xyMmQvEVr","colab_type":"text"},"source":["### Evaluation on Validation Dataset"]},{"cell_type":"code","metadata":{"id":"y2mfb6cjvEVs","colab_type":"code","colab":{}},"source":["val_gen = generate_batch(X_test, y_test, batch_size = 1)\n","k=-1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u55pAeB4vEVu","colab_type":"code","outputId":"1f171520-8551-4574-93f6-51221fea0e70","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1561640014029,"user_tz":-330,"elapsed":897,"user":{"displayName":"Rishav Ray","photoUrl":"","userId":"01504729190311909716"}}},"source":["k+=1\n","(input_seq, actual_output), _ = next(val_gen)\n","decoded_sentence = decode_sequence(input_seq)\n","print('Input English sentence:', X_test[k:k+1].values[0])\n","print('Actual Hindi Translation:', y_test[k:k+1].values[0][6:-4])\n","print('Predicted Hindi Translation:', decoded_sentence[:-4])"],"execution_count":82,"outputs":[{"output_type":"stream","text":["Input English sentence: i met mary yesterday\n","Actual Hindi Translation:  मैं कल मेरी से मिला था। \n","Predicted Hindi Translation:  मैं तुम्हारे पास एक मिलने का जवाब है। \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gN_SK9dhvEXk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}